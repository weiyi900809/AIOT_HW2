#!/usr/bin/env python3
"""
Wine Quality Model Training Script (Enhanced Version)
åŒ…å«ç‰¹å¾µé¸æ“‡ã€æ¨¡å‹è©•ä¼°å’Œé æ¸¬å€é–“è¨ˆç®—
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler
from sklearn.feature_selection import RFE, RFECV
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import joblib
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

print("="*80)
print("Wine Quality Model Training - Enhanced Version")
print("åŒ…å«ç‰¹å¾µé¸æ“‡èˆ‡å®Œæ•´æ¨¡å‹è©•ä¼°")
print("="*80)

# ============================================================================
# 1. æ•¸æ“šåŠ è¼‰
# ============================================================================
print("\n[1] æ•¸æ“šåŠ è¼‰...")
url = "https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv"

try:
    df = pd.read_csv(url, sep=';')
    print(f"âœ“ æ•¸æ“šé›†åŠ è¼‰æˆåŠŸï¼å…± {df.shape[0]} ç­†è¨˜éŒ„")
except:
    print("âœ— ç„¡æ³•å¾ UCI åŠ è¼‰ï¼Œå˜—è©¦å¾æœ¬åœ°åŠ è¼‰...")
    df = pd.read_csv('winequality-red.csv', sep=';')

# æ•¸æ“šæ¸…ç†
df_clean = df.drop_duplicates()
print(f"âœ“ ç§»é™¤é‡è¤‡å€¼å¾Œï¼š{df_clean.shape[0]} ç­†è¨˜éŒ„")

# åˆ†é›¢ç‰¹å¾µå’Œç›®æ¨™
X = df_clean.drop('quality', axis=1)
y = df_clean['quality']

print(f"\nç‰¹å¾µæ•¸é‡: {X.shape[1]}")
print(f"ç‰¹å¾µåç¨±: {list(X.columns)}")

# ============================================================================
# 2. ç‰¹å¾µé¸æ“‡ (Feature Selection)
# ============================================================================
print("\n" + "="*80)
print("[2] ç‰¹å¾µé¸æ“‡ (Recursive Feature Elimination with Cross-Validation)")
print("="*80)

# åˆ†å‰²æ•¸æ“šï¼ˆç”¨æ–¼ç‰¹å¾µé¸æ“‡ï¼‰
X_train_temp, X_test_temp, y_train_temp, y_test_temp = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# æ¨™æº–åŒ–ï¼ˆç‰¹å¾µé¸æ“‡éšæ®µï¼‰
scaler_temp = StandardScaler()
X_train_scaled_temp = scaler_temp.fit_transform(X_train_temp)
X_test_scaled_temp = scaler_temp.transform(X_test_temp)

# ä½¿ç”¨ RFECV é€²è¡Œç‰¹å¾µé¸æ“‡ï¼ˆè‡ªå‹•é¸æ“‡æœ€ä½³ç‰¹å¾µæ•¸é‡ï¼‰
print("\nåŸ·è¡Œ RFECV ç‰¹å¾µé¸æ“‡...")
base_model = LinearRegression()
rfecv = RFECV(
    estimator=base_model,
    step=1,
    cv=5,
    scoring='r2',
    min_features_to_select=5
)

rfecv.fit(X_train_scaled_temp, y_train_temp)

print(f"\nâœ“ æœ€ä½³ç‰¹å¾µæ•¸é‡: {rfecv.n_features_}")
print(f"âœ“ æ‰€é¸ç‰¹å¾µ: {list(X.columns[rfecv.support_])}")

# é¡¯ç¤ºç‰¹å¾µæ’å
feature_ranking = pd.DataFrame({
    'ç‰¹å¾µåç¨±': X.columns,
    'æ˜¯å¦é¸ä¸­': rfecv.support_,
    'æ’å': rfecv.ranking_
}).sort_values('æ’å')

print("\nç‰¹å¾µé¸æ“‡çµæœ:")
print(feature_ranking)

# å„²å­˜ç‰¹å¾µé¸æ“‡è³‡è¨Š
selected_features = X.columns[rfecv.support_].tolist()
joblib.dump(selected_features, 'selected_features.pkl')
joblib.dump(rfecv, 'feature_selector.pkl')

# è¦–è¦ºåŒ–äº¤å‰é©—è­‰åˆ†æ•¸
plt.figure(figsize=(10, 6))
plt.plot(range(1, len(rfecv.cv_results_['mean_test_score']) + 1), 
         rfecv.cv_results_['mean_test_score'], 
         marker='o', linewidth=2)
plt.xlabel('ç‰¹å¾µæ•¸é‡', fontsize=12)
plt.ylabel('äº¤å‰é©—è­‰ RÂ² åˆ†æ•¸', fontsize=12)
plt.title('RFECV: ç‰¹å¾µæ•¸é‡ vs. æ¨¡å‹æ€§èƒ½', fontsize=14, fontweight='bold')
plt.grid(True, alpha=0.3)
plt.axvline(x=rfecv.n_features_, color='r', linestyle='--', 
            label=f'æœ€ä½³ç‰¹å¾µæ•¸: {rfecv.n_features_}')
plt.legend()
plt.tight_layout()
plt.savefig('feature_selection_cv_scores.png', dpi=300, bbox_inches='tight')
print("\nâœ“ ç‰¹å¾µé¸æ“‡åœ–è¡¨å·²å„²å­˜: feature_selection_cv_scores.png")
plt.close()

# ============================================================================
# 3. ä½¿ç”¨é¸å®šç‰¹å¾µé‡æ–°è¨“ç·´æ¨¡å‹
# ============================================================================
print("\n" + "="*80)
print("[3] ä½¿ç”¨é¸å®šç‰¹å¾µé‡æ–°è¨“ç·´æ¨¡å‹")
print("="*80)

# åªä¿ç•™é¸å®šçš„ç‰¹å¾µ
X_selected = X[selected_features]

# é‡æ–°åˆ†å‰²æ•¸æ“š
X_train, X_test, y_train, y_test = train_test_split(
    X_selected, y, test_size=0.2, random_state=42
)

print(f"\nè¨“ç·´é›†å¤§å°: {X_train.shape}")
print(f"æ¸¬è©¦é›†å¤§å°: {X_test.shape}")

# æ¨™æº–åŒ–ç‰¹å¾µ
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# è¨“ç·´æœ€çµ‚æ¨¡å‹
model = LinearRegression()
model.fit(X_train_scaled, y_train)

print("\nâœ“ æ¨¡å‹è¨“ç·´å®Œæˆï¼")

# æ¨¡å‹ä¿‚æ•¸
coefficients = pd.DataFrame({
    'ç‰¹å¾µ': selected_features,
    'ä¿‚æ•¸': model.coef_
}).sort_values(by='ä¿‚æ•¸', key=abs, ascending=False)

print("\næ¨¡å‹ä¿‚æ•¸ (æŒ‰çµ•å°å€¼æ’åº):")
print(coefficients)

# ============================================================================
# 4. æ¨¡å‹è©•ä¼° (Model Evaluation)
# ============================================================================
print("\n" + "="*80)
print("[4] æ¨¡å‹è©•ä¼°")
print("="*80)

# é æ¸¬
y_train_pred = model.predict(X_train_scaled)
y_test_pred = model.predict(X_test_scaled)

# è¨“ç·´é›†æ€§èƒ½
train_r2 = r2_score(y_train, y_train_pred)
train_mae = mean_absolute_error(y_train, y_train_pred)
train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))

print("\nè¨“ç·´é›†æ€§èƒ½:")
print(f"  RÂ² Score: {train_r2:.4f}")
print(f"  MAE: {train_mae:.4f}")
print(f"  RMSE: {train_rmse:.4f}")

# æ¸¬è©¦é›†æ€§èƒ½
test_r2 = r2_score(y_test, y_test_pred)
test_mae = mean_absolute_error(y_test, y_test_pred)
test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))

print("\næ¸¬è©¦é›†æ€§èƒ½:")
print(f"  RÂ² Score: {test_r2:.4f}")
print(f"  MAE: {test_mae:.4f}")
print(f"  RMSE: {test_rmse:.4f}")

# äº¤å‰é©—è­‰
print("\nåŸ·è¡Œ 5 æŠ˜äº¤å‰é©—è­‰...")
cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='r2')
print(f"äº¤å‰é©—è­‰ RÂ² åˆ†æ•¸: {cv_scores}")
print(f"å¹³å‡ RÂ² Score: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})")

# æ®˜å·®åˆ†æ
residuals = y_test - y_test_pred
print("\næ®˜å·®çµ±è¨ˆ:")
print(f"  æ®˜å·®å‡å€¼: {residuals.mean():.4f}")
print(f"  æ®˜å·®æ¨™æº–å·®: {residuals.std():.4f}")
print(f"  æœ€å°æ®˜å·®: {residuals.min():.4f}")
print(f"  æœ€å¤§æ®˜å·®: {residuals.max():.4f}")

# ============================================================================
# 5. è¨ˆç®—é æ¸¬å€é–“å’Œä¿¡è³´å€é–“
# ============================================================================
print("\n" + "="*80)
print("[5] è¨ˆç®—é æ¸¬å€é–“å’Œä¿¡è³´å€é–“")
print("="*80)

# è¨ˆç®—æ¨™æº–èª¤å·® (ç”¨æ–¼é æ¸¬å€é–“)
mse = mean_squared_error(y_train, y_train_pred)
std_error = np.sqrt(mse)

# è¨ˆç®—ä¿¡è³´å€é–“å’Œé æ¸¬å€é–“æ‰€éœ€çš„åƒæ•¸
n = len(y_train)
k = X_train_scaled.shape[1]  # ç‰¹å¾µæ•¸é‡
dof = n - k - 1  # è‡ªç”±åº¦

from scipy import stats
t_value = stats.t.ppf(0.975, dof)  # 95% ä¿¡è³´æ°´æº–

print(f"\næ¨™æº–èª¤å·® (Standard Error): {std_error:.4f}")
print(f"t å€¼ (95% ä¿¡è³´æ°´æº–): {t_value:.4f}")
print(f"è‡ªç”±åº¦: {dof}")

# è¨ˆç®—æ¸¬è©¦é›†çš„é æ¸¬å€é–“
# é æ¸¬å€é–“ = prediction Â± t * std_error * sqrt(1 + 1/n + (x-x_mean)^2/sum((x-x_mean)^2))
# ç°¡åŒ–ç‰ˆæœ¬: prediction Â± t * std_error * sqrt(1 + 1/n)
prediction_interval_width = t_value * std_error * np.sqrt(1 + 1/n)

# è¨ˆç®—ä¿¡è³´å€é–“ (é‡å°å‡å€¼)
# ä¿¡è³´å€é–“ = prediction Â± t * std_error / sqrt(n)
confidence_interval_width = t_value * std_error / np.sqrt(n)

print(f"\né æ¸¬å€é–“å¯¬åº¦ (å–®å´): Â±{prediction_interval_width:.4f}")
print(f"ä¿¡è³´å€é–“å¯¬åº¦ (å–®å´): Â±{confidence_interval_width:.4f}")

# å„²å­˜å€é–“è¨ˆç®—åƒæ•¸
interval_params = {
    'std_error': std_error,
    't_value': t_value,
    'n': n,
    'prediction_interval_width': prediction_interval_width,
    'confidence_interval_width': confidence_interval_width
}
joblib.dump(interval_params, 'interval_params.pkl')

# ============================================================================
# 6. ç”Ÿæˆè©•ä¼°åœ–è¡¨
# ============================================================================
print("\n" + "="*80)
print("[6] ç”Ÿæˆè©•ä¼°åœ–è¡¨")
print("="*80)

# å‰µå»ºç¶œåˆè©•ä¼°åœ–
fig, axes = plt.subplots(2, 2, figsize=(15, 12))

# åœ–1: é æ¸¬å€¼ vs å¯¦éš›å€¼ (è¨“ç·´é›†)
axes[0, 0].scatter(y_train, y_train_pred, alpha=0.6, edgecolors='k')
axes[0, 0].plot([y_train.min(), y_train.max()], 
                [y_train.min(), y_train.max()], 'r--', lw=2)
axes[0, 0].set_xlabel('å¯¦éš›å“è³ª', fontsize=11)
axes[0, 0].set_ylabel('é æ¸¬å“è³ª', fontsize=11)
axes[0, 0].set_title(f'è¨“ç·´é›†: é æ¸¬ vs å¯¦éš›\nRÂ² = {train_r2:.4f}', 
                     fontsize=12, fontweight='bold')
axes[0, 0].grid(True, alpha=0.3)

# åœ–2: é æ¸¬å€¼ vs å¯¦éš›å€¼ (æ¸¬è©¦é›†)
axes[0, 1].scatter(y_test, y_test_pred, alpha=0.6, edgecolors='k', color='orange')
axes[0, 1].plot([y_test.min(), y_test.max()], 
                [y_test.min(), y_test.max()], 'r--', lw=2)
axes[0, 1].set_xlabel('å¯¦éš›å“è³ª', fontsize=11)
axes[0, 1].set_ylabel('é æ¸¬å“è³ª', fontsize=11)
axes[0, 1].set_title(f'æ¸¬è©¦é›†: é æ¸¬ vs å¯¦éš›\nRÂ² = {test_r2:.4f}', 
                     fontsize=12, fontweight='bold')
axes[0, 1].grid(True, alpha=0.3)

# åœ–3: æ®˜å·®åœ–
axes[1, 0].scatter(y_test_pred, residuals, alpha=0.6, edgecolors='k', color='green')
axes[1, 0].axhline(y=0, color='r', linestyle='--', lw=2)
axes[1, 0].set_xlabel('é æ¸¬å€¼', fontsize=11)
axes[1, 0].set_ylabel('æ®˜å·®', fontsize=11)
axes[1, 0].set_title('æ®˜å·®åœ–', fontsize=12, fontweight='bold')
axes[1, 0].grid(True, alpha=0.3)

# åœ–4: æ®˜å·®åˆ†å¸ƒ
axes[1, 1].hist(residuals, bins=30, edgecolor='k', alpha=0.7, color='purple')
axes[1, 1].axvline(x=0, color='r', linestyle='--', lw=2)
axes[1, 1].set_xlabel('æ®˜å·®', fontsize=11)
axes[1, 1].set_ylabel('é »ç‡', fontsize=11)
axes[1, 1].set_title(f'æ®˜å·®åˆ†å¸ƒ\nå‡å€¼={residuals.mean():.4f}, æ¨™æº–å·®={residuals.std():.4f}', 
                     fontsize=12, fontweight='bold')
axes[1, 1].grid(True, alpha=0.3, axis='y')

plt.tight_layout()
plt.savefig('model_evaluation_plots.png', dpi=300, bbox_inches='tight')
print("\nâœ“ æ¨¡å‹è©•ä¼°åœ–è¡¨å·²å„²å­˜: model_evaluation_plots.png")
plt.close()

# ç‰¹å¾µé‡è¦æ€§åœ–
plt.figure(figsize=(10, 6))
coefficients_sorted = coefficients.sort_values('ä¿‚æ•¸')
colors = ['red' if x < 0 else 'green' for x in coefficients_sorted['ä¿‚æ•¸']]
plt.barh(coefficients_sorted['ç‰¹å¾µ'], coefficients_sorted['ä¿‚æ•¸'], color=colors, alpha=0.7)
plt.xlabel('ä¿‚æ•¸å€¼', fontsize=12)
plt.ylabel('ç‰¹å¾µ', fontsize=12)
plt.title('ç‰¹å¾µé‡è¦æ€§ (æ¨¡å‹ä¿‚æ•¸)', fontsize=14, fontweight='bold')
plt.axvline(x=0, color='black', linestyle='-', linewidth=0.8)
plt.grid(True, alpha=0.3, axis='x')
plt.tight_layout()
plt.savefig('feature_importance.png', dpi=300, bbox_inches='tight')
print("âœ“ ç‰¹å¾µé‡è¦æ€§åœ–è¡¨å·²å„²å­˜: feature_importance.png")
plt.close()

# ============================================================================
# 7. ä¿å­˜æ¨¡å‹å’Œç›¸é—œæª”æ¡ˆ
# ============================================================================
print("\n" + "="*80)
print("[7] ä¿å­˜æ¨¡å‹å’Œç›¸é—œæª”æ¡ˆ")
print("="*80)

joblib.dump(model, 'wine_quality_model.pkl')
joblib.dump(scaler, 'feature_scaler.pkl')
joblib.dump(selected_features, 'feature_names.pkl')

# ä¿å­˜æ¨¡å‹è©•ä¼°çµæœ
evaluation_results = {
    'train_r2': train_r2,
    'train_mae': train_mae,
    'train_rmse': train_rmse,
    'test_r2': test_r2,
    'test_mae': test_mae,
    'test_rmse': test_rmse,
    'cv_scores': cv_scores,
    'cv_mean': cv_scores.mean(),
    'cv_std': cv_scores.std(),
    'coefficients': coefficients.to_dict(),
    'n_features_original': X.shape[1],
    'n_features_selected': len(selected_features),
    'selected_features': selected_features
}
joblib.dump(evaluation_results, 'evaluation_results.pkl')

print("\nâœ“ æ¨¡å‹å·²ä¿å­˜ç‚º: wine_quality_model.pkl")
print("âœ“ Scaler å·²ä¿å­˜ç‚º: feature_scaler.pkl")
print("âœ“ ç‰¹å¾µåç¨±å·²ä¿å­˜ç‚º: feature_names.pkl")
print("âœ“ è©•ä¼°çµæœå·²ä¿å­˜ç‚º: evaluation_results.pkl")
print("âœ“ å€é–“åƒæ•¸å·²ä¿å­˜ç‚º: interval_params.pkl")
print("âœ“ ç‰¹å¾µé¸æ“‡å™¨å·²ä¿å­˜ç‚º: feature_selector.pkl")
print("âœ“ é¸å®šç‰¹å¾µå·²ä¿å­˜ç‚º: selected_features.pkl")

print("\n" + "="*80)
print("æ¨¡å‹è¨“ç·´èˆ‡è©•ä¼°å®Œæˆï¼")
print("="*80)

# è¼¸å‡ºæœ€çµ‚ç¸½çµ
print("\nğŸ“Š æœ€çµ‚æ¨¡å‹ç¸½çµ:")
print(f"  åŸå§‹ç‰¹å¾µæ•¸: {X.shape[1]}")
print(f"  é¸å®šç‰¹å¾µæ•¸: {len(selected_features)}")
print(f"  æ¸¬è©¦é›† RÂ²: {test_r2:.4f}")
print(f"  æ¸¬è©¦é›† MAE: {test_mae:.4f}")
print(f"  æ¸¬è©¦é›† RMSE: {test_rmse:.4f}")
print(f"  äº¤å‰é©—è­‰ RÂ²: {cv_scores.mean():.4f} (Â±{cv_scores.std()*2:.4f})")
